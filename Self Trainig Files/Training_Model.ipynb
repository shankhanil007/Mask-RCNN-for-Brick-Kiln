{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvG21h_osaZg"
      },
      "source": [
        "# !git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAKrwAvZsdn2"
      },
      "source": [
        "import os\r\n",
        "os.chdir(\"Mask_RCNN/samples\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp5qhsuB8hqX",
        "outputId": "e715b30e-2e6c-4445-a269-66c43ce98f4e"
      },
      "source": [
        "# %tensorflow_version 1.x\r\n",
        "# import tensorflow\r\n",
        "# print(tensorflow.__version__)\r\n",
        "# import tensorflow.compat.v1 as tf\r\n",
        "# tf.disable_v2_behavior() \r\n",
        "!pip3 install keras==2.2.5\r\n",
        "!pip install tensorflow==1.15.0rc2\r\n",
        "# !pip install Keras==2.3.1 tensorflow==2.1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Collecting tensorflow==1.15.0rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/bf/ee59aeef074bcecf7421380b3ed6c6880c04c059acee72cb8591beeaad91/tensorflow-1.15.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc2) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (51.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0rc2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc2) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "Successfully installed tensorboard-1.15.0 tensorflow-1.15.0rc2 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgRBvp4Hssgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3f2b1b-5578-4405-97b2-06a88c9a8afb"
      },
      "source": [
        "# COCO related libraries\r\n",
        "import sys\r\n",
        "# Root directory of the project\r\n",
        "ROOT_DIR = os.path.abspath(\"../\")\r\n",
        "\r\n",
        "# Import Mask RCNN\r\n",
        "sys.path.append(ROOT_DIR) \r\n",
        "# MaskRCNN libraries\r\n",
        "from mrcnn.config import Config\r\n",
        "import mrcnn.utils as utils\r\n",
        "from mrcnn import visualize\r\n",
        "import mrcnn.model as modellib\r\n",
        "\r\n",
        "# Import COCO config\r\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\r\n",
        "import coco\r\n",
        "\r\n",
        "\r\n",
        "# Misc\r\n",
        "import sys\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "from PIL import Image, ImageDraw"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUeldgtssvSf"
      },
      "source": [
        "# from google.colab import drive\r\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJalqTHotLHs"
      },
      "source": [
        "\r\n",
        "# Number of classes in dataset. Must be of type integer\r\n",
        "NUM_CLASSES = 3\r\n",
        "\r\n",
        "# Relative path to .h5 weights file\r\n",
        "WEIGHTS_FILE = None\r\n",
        "\r\n",
        "# Relative path to annotations JSON file\r\n",
        "TRAIN_ANNOTATIONS_FILE = os.path.abspath(\"../../drive/MyDrive/MRCNN model weights/Dataset/Train/ann/train.json\")\r\n",
        "\r\n",
        "# Relative path to directory of images that pertain to annotations file\r\n",
        "TRAIN_ANNOTATION_IMAGE_DIR = os.path.abspath(\"../../drive/MyDrive/MRCNN model weights/Dataset/Train/img\")\r\n",
        "\r\n",
        "# Relative path to annotations JSON file\r\n",
        "VALIDATION_ANNOTATIONS_FILE = os.path.abspath(\"../../drive/MyDrive/MRCNN model weights/Dataset/Val/ann/Val.json\")\r\n",
        "\r\n",
        "# Relative path to directory of images that pertain to annotations file\r\n",
        "VALIDATION_ANNOTATION_IMAGE_DIR = os.path.abspath(\"../../drive/MyDrive/MRCNN model weights/Dataset/Val/img\")\r\n",
        "\r\n",
        "# Number of epochs to train dataset on\r\n",
        "NUM_EPOCHS = 10\r\n",
        "\r\n",
        "MODEL_NAME = \"model_2\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPi_zJSG45o4"
      },
      "source": [
        "# Directory to save logs and trained model\r\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm8q94Xi5Ifm"
      },
      "source": [
        "\r\n",
        "\r\n",
        "class TrainConfig(coco.CocoConfig):\r\n",
        "    \"\"\"\r\n",
        "    \"\"\"\r\n",
        "    # Give the configuration a recognizable name\r\n",
        "    NAME = MODEL_NAME\r\n",
        "\r\n",
        "    # Train on 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\r\n",
        "    GPU_COUNT = 1\r\n",
        "    IMAGES_PER_GPU = 1\r\n",
        "\r\n",
        "    # Number of classes (including background)\r\n",
        "    NUM_CLASSES = 1 + 1\r\n",
        "\r\n",
        "    # Min and max image dimensions\r\n",
        "    # IMAGE_MIN_DIM = 1152\r\n",
        "    # IMAGE_MAX_DIM = 1280\r\n",
        "\r\n",
        "    # You can experiment with this number to see if it improves training\r\n",
        "    STEPS_PER_EPOCH = 50\r\n",
        "\r\n",
        "    # This is how often validation is run. If you are using too much hard drive space\r\n",
        "    # on saved models (in the MODEL_DIR), try making this value larger.\r\n",
        "    VALIDATION_STEPS = 50\r\n",
        "    \r\n",
        "    # Matterport originally used resnet101, but I downsized to fit it on my graphics card\r\n",
        "    BACKBONE = 'resnet101'\r\n",
        "\r\n",
        "    # To be honest, I haven't taken the time to figure out what these do\r\n",
        "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\r\n",
        "    \r\n",
        "    # Changed to 512 because that's how many the original MaskRCNN paper used\r\n",
        "    TRAIN_ROIS_PER_IMAGE = 200\r\n",
        "    MAX_GT_INSTANCES = 114\r\n",
        "    POST_NMS_ROIS_INFERENCE = 1000 \r\n",
        "    POST_NMS_ROIS_TRAINING = 2000 \r\n",
        "    \r\n",
        "    DETECTION_MAX_INSTANCES = 114\r\n",
        "    DETECTION_MIN_CONFIDENCE = 0.1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0Ipy-hE6RE-",
        "outputId": "0e62f4ab-5a41-4b35-9217-ebf8b28cd403"
      },
      "source": [
        "TrainConfig().display()\r\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        114\n",
            "DETECTION_MIN_CONFIDENCE       0.1\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               114\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           model_2\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                50\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdZdLSU78t8M"
      },
      "source": [
        "class CocoLikeDataset(utils.Dataset):\r\n",
        "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\r\n",
        "        See http://cocodataset.org/#home for more information.\r\n",
        "    \"\"\"\r\n",
        "    def load_data(self, annotation_json, images_dir):\r\n",
        "        \"\"\" Load the coco-like dataset from json\r\n",
        "        Args:\r\n",
        "            annotation_json: The path to the coco annotations json file\r\n",
        "            images_dir: The directory holding the images referred to by the json file\r\n",
        "        \"\"\"\r\n",
        "        # Load json from file\r\n",
        "        json_file = open(annotation_json)\r\n",
        "        coco_json = json.load(json_file)\r\n",
        "        json_file.close()\r\n",
        "        \r\n",
        "        # Add the class names using the base method from utils.Dataset\r\n",
        "        source_name = \"coco_like\"\r\n",
        "        for category in coco_json['categories']:\r\n",
        "            class_id = category['id']\r\n",
        "            class_name = category['name']\r\n",
        "            if class_id < 1:\r\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\r\n",
        "                return\r\n",
        "            \r\n",
        "            self.add_class(source_name, class_id, class_name)\r\n",
        "        \r\n",
        "        # Get all annotations\r\n",
        "        annotations = {}\r\n",
        "        for annotation in coco_json['annotations']:\r\n",
        "            image_id = annotation['image_id']\r\n",
        "            if image_id not in annotations:\r\n",
        "                annotations[image_id] = []\r\n",
        "            annotations[image_id].append(annotation)\r\n",
        "        \r\n",
        "        # Get all images and add them to the dataset\r\n",
        "        seen_images = {}\r\n",
        "        for image in coco_json['images']:\r\n",
        "            image_id = image['id']\r\n",
        "            if image_id in seen_images:\r\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\r\n",
        "            else:\r\n",
        "                seen_images[image_id] = image\r\n",
        "                try:\r\n",
        "                    image_file_name = image['file_name']\r\n",
        "                    image_width = image['width']\r\n",
        "                    image_height = image['height']\r\n",
        "                except KeyError as key:\r\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\r\n",
        "                \r\n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\r\n",
        "                image_annotations = annotations[image_id]\r\n",
        "                \r\n",
        "                # Add the image using the base method from utils.Dataset\r\n",
        "                self.add_image(\r\n",
        "                    source=source_name,\r\n",
        "                    image_id=image_id,\r\n",
        "                    path=image_path,\r\n",
        "                    width=image_width,\r\n",
        "                    height=image_height,\r\n",
        "                    annotations=image_annotations\r\n",
        "                )\r\n",
        "                \r\n",
        "    def load_mask(self, image_id):\r\n",
        "        \"\"\" Load instance masks for the given image.\r\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\r\n",
        "        Args:\r\n",
        "            image_id: The id of the image to load masks for\r\n",
        "        Returns:\r\n",
        "            masks: A bool array of shape [height, width, instance count] with\r\n",
        "                one mask per instance.\r\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\r\n",
        "        \"\"\"\r\n",
        "        image_info = self.image_info[image_id]\r\n",
        "        annotations = image_info['annotations']\r\n",
        "        instance_masks = []\r\n",
        "        class_ids = []\r\n",
        "        \r\n",
        "        for annotation in annotations:\r\n",
        "            class_id = annotation['category_id']\r\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\r\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\r\n",
        "            for segmentation in annotation['segmentation']:\r\n",
        "                mask_draw.polygon(segmentation, fill=1)\r\n",
        "                bool_array = np.array(mask) > 0\r\n",
        "                instance_masks.append(bool_array)\r\n",
        "                class_ids.append(class_id)\r\n",
        "\r\n",
        "        mask = np.dstack(instance_masks)\r\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\r\n",
        "        \r\n",
        "        return mask, class_ids"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFS6LUr78yR8"
      },
      "source": [
        "dataset_train = CocoLikeDataset()\r\n",
        "dataset_train.load_data(TRAIN_ANNOTATIONS_FILE, TRAIN_ANNOTATION_IMAGE_DIR)\r\n",
        "dataset_train.prepare()\r\n",
        "\r\n",
        "dataset_val = CocoLikeDataset()\r\n",
        "dataset_val.load_data(VALIDATION_ANNOTATIONS_FILE, VALIDATION_ANNOTATION_IMAGE_DIR)\r\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOV-LRh81Ca"
      },
      "source": [
        "model = modellib.MaskRCNN(mode = \"training\", config = TrainConfig(), model_dir = MODEL_DIR)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEYrkEQr88k5"
      },
      "source": [
        "if WEIGHTS_FILE is not None:\r\n",
        "    model.load_weights(WEIGHTS_FILE, by_name = True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH2XTyeP9At_",
        "outputId": "7088acb9-9cd6-4084-ec26-ef471e9ad313"
      },
      "source": [
        "start_train = time.time()\r\n",
        "model.train(dataset_train, dataset_val, learning_rate = TrainConfig().LEARNING_RATE, epochs = NUM_EPOCHS, layers = 'all')\r\n",
        "end_train = time.time()\r\n",
        "minutes = round((end_train - start_train) / 60, 2)\r\n",
        "print(f'Training took {minutes} minutes')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/Mask_RCNN/logs/model_220210112T0612/mask_rcnn_model_2_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 174s 3s/step - loss: 9.9375 - rpn_class_loss: 0.8718 - rpn_bbox_loss: 5.3262 - mrcnn_class_loss: 0.7909 - mrcnn_bbox_loss: 2.5231 - mrcnn_mask_loss: 0.4254 - val_loss: 6.7394 - val_rpn_class_loss: 1.3104 - val_rpn_bbox_loss: 3.2746 - val_mrcnn_class_loss: 0.2226 - val_mrcnn_bbox_loss: 1.3431 - val_mrcnn_mask_loss: 0.5886\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 53s 1s/step - loss: 3.0327 - rpn_class_loss: 0.1930 - rpn_bbox_loss: 1.1256 - mrcnn_class_loss: 0.2862 - mrcnn_bbox_loss: 0.8587 - mrcnn_mask_loss: 0.5691 - val_loss: 4.7871 - val_rpn_class_loss: 0.7027 - val_rpn_bbox_loss: 2.4194 - val_mrcnn_class_loss: 0.3866 - val_mrcnn_bbox_loss: 0.7258 - val_mrcnn_mask_loss: 0.5525\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.9696 - rpn_class_loss: 0.0761 - rpn_bbox_loss: 0.6127 - mrcnn_class_loss: 0.2813 - mrcnn_bbox_loss: 0.4661 - mrcnn_mask_loss: 0.5335 - val_loss: 4.3661 - val_rpn_class_loss: 0.6564 - val_rpn_bbox_loss: 2.0572 - val_mrcnn_class_loss: 0.4058 - val_mrcnn_bbox_loss: 0.6949 - val_mrcnn_mask_loss: 0.5518\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.7038 - rpn_class_loss: 0.0543 - rpn_bbox_loss: 0.4664 - mrcnn_class_loss: 0.2854 - mrcnn_bbox_loss: 0.3788 - mrcnn_mask_loss: 0.5189 - val_loss: 4.2730 - val_rpn_class_loss: 0.6977 - val_rpn_bbox_loss: 1.9459 - val_mrcnn_class_loss: 0.4703 - val_mrcnn_bbox_loss: 0.6542 - val_mrcnn_mask_loss: 0.5050\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 57s 1s/step - loss: 1.4640 - rpn_class_loss: 0.0376 - rpn_bbox_loss: 0.3269 - mrcnn_class_loss: 0.2802 - mrcnn_bbox_loss: 0.3198 - mrcnn_mask_loss: 0.4995 - val_loss: 4.1610 - val_rpn_class_loss: 0.6624 - val_rpn_bbox_loss: 1.8913 - val_mrcnn_class_loss: 0.4520 - val_mrcnn_bbox_loss: 0.6056 - val_mrcnn_mask_loss: 0.5496\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 58s 1s/step - loss: 1.1042 - rpn_class_loss: 0.0147 - rpn_bbox_loss: 0.1505 - mrcnn_class_loss: 0.2178 - mrcnn_bbox_loss: 0.2262 - mrcnn_mask_loss: 0.4949 - val_loss: 4.1397 - val_rpn_class_loss: 0.5636 - val_rpn_bbox_loss: 1.9924 - val_mrcnn_class_loss: 0.4713 - val_mrcnn_bbox_loss: 0.5831 - val_mrcnn_mask_loss: 0.5293\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 57s 1s/step - loss: 1.0843 - rpn_class_loss: 0.0160 - rpn_bbox_loss: 0.1921 - mrcnn_class_loss: 0.1851 - mrcnn_bbox_loss: 0.2106 - mrcnn_mask_loss: 0.4804 - val_loss: 3.9626 - val_rpn_class_loss: 0.5603 - val_rpn_bbox_loss: 1.8652 - val_mrcnn_class_loss: 0.4553 - val_mrcnn_bbox_loss: 0.5534 - val_mrcnn_mask_loss: 0.5284\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 58s 1s/step - loss: 0.8658 - rpn_class_loss: 0.0109 - rpn_bbox_loss: 0.0782 - mrcnn_class_loss: 0.1579 - mrcnn_bbox_loss: 0.1553 - mrcnn_mask_loss: 0.4635 - val_loss: 4.1360 - val_rpn_class_loss: 0.6339 - val_rpn_bbox_loss: 1.8847 - val_mrcnn_class_loss: 0.5015 - val_mrcnn_bbox_loss: 0.5952 - val_mrcnn_mask_loss: 0.5208\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 58s 1s/step - loss: 0.8787 - rpn_class_loss: 0.0083 - rpn_bbox_loss: 0.1143 - mrcnn_class_loss: 0.1660 - mrcnn_bbox_loss: 0.1488 - mrcnn_mask_loss: 0.4413 - val_loss: 4.0911 - val_rpn_class_loss: 0.6890 - val_rpn_bbox_loss: 1.9117 - val_mrcnn_class_loss: 0.4465 - val_mrcnn_bbox_loss: 0.5449 - val_mrcnn_mask_loss: 0.4990\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 57s 1s/step - loss: 0.9647 - rpn_class_loss: 0.0131 - rpn_bbox_loss: 0.2075 - mrcnn_class_loss: 0.1457 - mrcnn_bbox_loss: 0.1680 - mrcnn_mask_loss: 0.4304 - val_loss: 4.0989 - val_rpn_class_loss: 0.6227 - val_rpn_bbox_loss: 1.9588 - val_mrcnn_class_loss: 0.4658 - val_mrcnn_bbox_loss: 0.5530 - val_mrcnn_mask_loss: 0.4985\n",
            "Training took 19.01 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU4rq35MTBZT"
      },
      "source": [
        "\r\n",
        "# COCO related libraries\r\n",
        "import coco\r\n",
        "from pycocotools.coco import COCO\r\n",
        "\r\n",
        "# MaskRCNN libraries\r\n",
        "from mrcnn import utils, visualize\r\n",
        "from mrcnn import model as modellib\r\n",
        "\r\n",
        "# Misc\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import skimage.io\r\n",
        "import random\r\n",
        "import json\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esr_uJj1UQUF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}